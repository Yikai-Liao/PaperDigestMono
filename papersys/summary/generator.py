"""Summary generation utilities powered by LLM configuration."""

from __future__ import annotations

from dataclasses import dataclass

from loguru import logger

from papersys.config.llm import LLMConfig

from .models import SummaryDocument, SummarySource


class SummaryGenerator:
    """Generate structured summaries using a lightweight LLM stub."""

    def __init__(self, llm_config: LLMConfig, *, default_language: str) -> None:
        self._client = _StubLLMClient(llm_config)
        self._default_language = default_language or "en"

    def generate(self, source: SummarySource) -> SummaryDocument:
        language = source.language or self._default_language
        logger.debug("Generating summary for {} using language {}", source.paper_id, language)
        sections = self._client.summarise(source, language=language)
        return SummaryDocument(
            paper_id=source.paper_id,
            title=source.title,
            language=language,
            sections=sections,
        )


@dataclass(slots=True)
class _StubLLMClient:
    """Tiny deterministic stand-in for a real LLM client."""

    config: LLMConfig

    def summarise(self, source: SummarySource, *, language: str) -> dict[str, str]:
        abstract = source.abstract.strip()
        if not abstract:
            abstract = "No abstract provided."
        highlights = _first_sentences(abstract, limit=2)
        bullets = "\n".join(f"- {item}" for item in highlights)
        body = (
            f"This summary was generated by {self.config.name} (alias {self.config.alias}).\n"
            f"Detected language: {language}.\n\n"
            f"Key observations:\n{bullets}\n\n"
            f"Full abstract:\n{abstract}"
        )
        return {
            "Highlights": "\n".join(highlights) or "No highlights available.",
            "Detailed Summary": body,
        }


def _first_sentences(text: str, *, limit: int) -> list[str]:
    sentences: list[str] = []
    for chunk in text.replace("\n", " ").split("."):
        cleaned = chunk.strip()
        if cleaned:
            sentences.append(cleaned + ".")
        if len(sentences) >= limit:
            break
    return sentences


__all__ = ["SummaryGenerator"]
